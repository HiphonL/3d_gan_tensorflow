{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D-GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import *\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "np.random.seed(1) \n",
    "tf.set_random_seed(1)\n",
    "\n",
    "training_epochs = 20001 # num of epochs to train discriminator and generator jointly\n",
    "batch_size = 64 # batch size for training the model\n",
    "\n",
    "# ---- max layer 256 for generator ---#\n",
    "#alpha_g = 0.001\n",
    "#alpha_d = 0.000018\n",
    "\n",
    "# ---- max layer 512 for generator ---#\n",
    "# okay from 3k to 8k epochs\n",
    "alpha_g = 0.0015\n",
    "alpha_d = 0.000024\n",
    "\n",
    "beta1 = 0.5 # the fraction factor used in the first momentum term from Adam optimizer\n",
    "logs_path = \"./3d_gan_log\" # directory to save the training log to\n",
    "train_sample_directory = './3d_gan/train_sample/' # directory to save the generated 3d model during training\n",
    "model_directory = './3d_gan/models' # directory to save trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read training 3D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir = './3D_Voxel_Files/'\n",
    "train_names = [f for f in os.listdir(train_dir) if f.endswith('_1')]\n",
    "\n",
    "chairs = []\n",
    "for f in train_names:\n",
    "    chairs.append(np.load(train_dir+f)) # load the binary array files\n",
    "train_chairs = np.array(chairs)\n",
    "train_chairs=train_chairs.reshape([988,32,32,32,1]) # turn train_chairs into 5D tensor [batch, depth, height, width, channels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_chairs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a batch of real 3D models\n",
    "def get_x(batch_size):\n",
    "    indices = np.random.randint(len(train_chairs), size=batch_size) # random sample real images\n",
    "    batch = train_chairs[indices] \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Larger generator with 512 filters at the first deconvolutional layer\n",
    "\n",
    "\n",
    "# when is_train=False, do not perform batch normalization\n",
    "def generator(z, batch_size=batch_size, is_train=True, reuse=False):\n",
    "    print '\\n Generator:'\n",
    "    \n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        tl.layers.set_name_reuse(reuse)\n",
    "    \n",
    "    # input of the network \n",
    "    gen_in = tl.layers.InputLayer(inputs=z, name='g/in')\n",
    "    # fully connected layer\n",
    "    # n_units: number of nodes in FC layer\n",
    "    gen_h0 = tl.layers.DenseLayer(layer=gen_in, n_units = 4*4*4*512,\n",
    "                                W_init = initializer,\n",
    "                                act = tf.identity, name='g/h0/lin')\n",
    "    #print '!!!gen_h0.outputs before reshape:',gen_h0.outputs\n",
    "    # reshape the fully connected layer to a 5D tensor [batch size, depth, height, width, channels]\n",
    "    # output size: batch_size*4*4*4*512\n",
    "    gen_h0 = tl.layers.ReshapeLayer(gen_h0, shape = [-1,4,4,4,512], name='g/h0/reshape')\n",
    "    # batch normalize weight parameters\n",
    "    gen_h0 = tl.layers.BatchNormLayer(gen_h0, is_train=is_train, gamma_init=tf.random_normal_initializer(1., 0.02), name='g/h0/batch_norm')\n",
    "    # apply activation function\n",
    "    gen_h0.outputs = tf.nn.relu(gen_h0.outputs, name='g/h0/relu')\n",
    "    #print '!!!gen_h0.outputs after reshape:',gen_h0.outputs \n",
    "    \n",
    "    # shape: [kernel_depth, kernel_height, kernel_width, output_channels, input_channels]\n",
    "    # output shape: [batch size, output_depth, output_height, output_width, output channels]\n",
    "    # strides: [stride on batch, depth, height, width, channels]\n",
    "    # act: activation function\n",
    "    # output size: batch_size*8*8*8*256\n",
    "    gen_h1 = tl.layers.DeConv3dLayer(layer=gen_h0,\n",
    "                                shape = [4,4,4,256,512],\n",
    "                                output_shape = [batch_size,8,8,8,256],\n",
    "                                strides=[1,2,2,2,1],\n",
    "                                W_init = initializer,\n",
    "                                act=tf.identity, name='g/h1/decon2d')\n",
    "    gen_h1 = tl.layers.BatchNormLayer(gen_h1, is_train=is_train, gamma_init=tf.random_normal_initializer(1., 0.02), name='g/h1/batch_norm')\n",
    "    gen_h1.outputs = tf.nn.relu(gen_h1.outputs, name='g/h1/relu')\n",
    "    #print '!!!gen_h1.outputs:',gen_h1.outputs\n",
    "\n",
    "    # output size: batch_size*16*16*16*128\n",
    "    gen_h2 = tl.layers.DeConv3dLayer(layer=gen_h1,\n",
    "                                shape = [4,4,4,128,256],\n",
    "                                output_shape = [batch_size,16,16,16,128],\n",
    "                                strides=[1,2,2,2,1],\n",
    "                                W_init = initializer,\n",
    "                                act=tf.identity, name='g/h2/decon2d')\n",
    "    gen_h2 = tl.layers.BatchNormLayer(gen_h2, is_train=is_train, gamma_init=tf.random_normal_initializer(1., 0.02), name='g/h2/batch_norm')\n",
    "    gen_h2.outputs = tf.nn.relu(gen_h2.outputs, name='g/h2/relu')\n",
    "    #print '!!!gen_h2.outputs:',gen_h2.outputs \n",
    "    \n",
    "    # output size: batch_size*32*32*32*1\n",
    "    gen_h3 = tl.layers.DeConv3dLayer(layer=gen_h2,\n",
    "                                shape = [4,4,4,1,128],\n",
    "                                output_shape = [batch_size,32,32,32,1],\n",
    "                                strides=[1,2,2,2,1],\n",
    "                                W_init = initializer,\n",
    "                                act=tf.identity, name='g/h3/decon2d')\n",
    "    gen_h3.outputs = tf.nn.sigmoid(gen_h3.outputs)\n",
    "    #print '!!!gen_h3.outputs:',gen_h3.outputs\n",
    "    \n",
    "    return gen_h3 # return the generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Smaller generator with 256 filters at the first deconvolutional layer\n",
    "\n",
    "# when is_train=False, do not perform batch normalization\n",
    "def generator1(z, batch_size=batch_size, is_train=True, reuse=False):\n",
    "    print '\\n Generator:'\n",
    "    \n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        tl.layers.set_name_reuse(reuse)\n",
    "    \n",
    "    # input of the network \n",
    "    gen_in = tl.layers.InputLayer(inputs=z, name='g/in')\n",
    "    # fully connected layer\n",
    "    # n_units: number of nodes in FC layer\n",
    "    gen_h0 = tl.layers.DenseLayer(layer=gen_in, n_units = 4*4*4*256,\n",
    "                                W_init = initializer,\n",
    "                                act = tf.identity, name='g/h0/lin')\n",
    "    #print '!!!gen_h0.outputs before reshape:',gen_h0.outputs\n",
    "    # reshape the fully connected layer to a 5D tensor [batch size, depth, height, width, channels]\n",
    "    # output size: batch_size*4*4*4*256\n",
    "    gen_h0 = tl.layers.ReshapeLayer(gen_h0, shape = [-1,4,4,4,256], name='g/h0/reshape')\n",
    "    # batch normalize weight parameters\n",
    "    gen_h0 = tl.layers.BatchNormLayer(gen_h0, is_train=is_train, gamma_init=tf.random_normal_initializer(1., 0.02), name='g/h0/batch_norm')\n",
    "    # apply activation function\n",
    "    gen_h0.outputs = tf.nn.relu(gen_h0.outputs, name='g/h0/relu')\n",
    "    #print '!!!gen_h0.outputs after reshape:',gen_h0.outputs \n",
    "    \n",
    "    # shape: [kernel_depth, kernel_height, kernel_width, output_channels, input_channels]\n",
    "    # output shape: [batch size, output_depth, output_height, output_width, output channels]\n",
    "    # strides: [stride on batch, depth, height, width, channels]\n",
    "    # act: activation function\n",
    "    # output size: batch_size*8*8*8*128\n",
    "    gen_h1 = tl.layers.DeConv3dLayer(layer=gen_h0,\n",
    "                                shape = [4,4,4,128,256],\n",
    "                                output_shape = [batch_size,8,8,8,128],\n",
    "                                strides=[1,2,2,2,1],\n",
    "                                W_init = initializer,\n",
    "                                act=tf.identity, name='g/h1/decon2d')\n",
    "    gen_h1 = tl.layers.BatchNormLayer(gen_h1, is_train=is_train, gamma_init=tf.random_normal_initializer(1., 0.02), name='g/h1/batch_norm')\n",
    "    gen_h1.outputs = tf.nn.relu(gen_h1.outputs, name='g/h1/relu')\n",
    "    #print '!!!gen_h1.outputs:',gen_h1.outputs\n",
    "\n",
    "    # output size: batch_size*16*16*16*64\n",
    "    gen_h2 = tl.layers.DeConv3dLayer(layer=gen_h1,\n",
    "                                shape = [4,4,4,64,128],\n",
    "                                output_shape = [batch_size,16,16,16,64],\n",
    "                                strides=[1,2,2,2,1],\n",
    "                                W_init = initializer,\n",
    "                                act=tf.identity, name='g/h2/decon2d')\n",
    "    gen_h2 = tl.layers.BatchNormLayer(gen_h2, is_train=is_train, gamma_init=tf.random_normal_initializer(1., 0.02), name='g/h2/batch_norm')\n",
    "    gen_h2.outputs = tf.nn.relu(gen_h2.outputs, name='g/h2/relu')\n",
    "    #print '!!!gen_h2.outputs:',gen_h2.outputs \n",
    "    \n",
    "    # output size: batch_size*32*32*32*1\n",
    "    gen_h3 = tl.layers.DeConv3dLayer(layer=gen_h2,\n",
    "                                shape = [4,4,4,1,64],\n",
    "                                output_shape = [batch_size,32,32,32,1],\n",
    "                                strides=[1,2,2,2,1],\n",
    "                                W_init = initializer,\n",
    "                                act=tf.identity, name='g/h3/decon2d')\n",
    "    gen_h3.outputs = tf.nn.sigmoid(gen_h3.outputs)\n",
    "    #print '!!!gen_h3.outputs:',gen_h3.outputs\n",
    "    \n",
    "    return gen_h3 # return the generator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# when is_train=False, do not perform batch normalization\n",
    "def discriminator(inputs, batch_size=batch_size, is_train=True, reuse=False):\n",
    "    print '\\n Discriminator:'\n",
    "    \n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        tl.layers.set_name_reuse(reuse)\n",
    "    \n",
    "    # Inputs size: batch_size*32*32*32*1 \n",
    "    dis_in = tl.layers.InputLayer(inputs, name='d/in')\n",
    "    #print '!!!dis_in:',\n",
    "    #dis_in.print_layers() \n",
    "    \n",
    "    # Creates 32 4*4*4 filters to convolve on the mini-batch of 32*32*32 chairs, also perform batch norm + leaky ReLU activation\n",
    "    # Set reuse=True allows discriminator to evaluate both real samples and generated samples \n",
    "    # shape: [kernel_depth, kernel_height, kernel_width, input_channels, output_channels]\n",
    "    # strides: [stride on batch, depth, height, width, channels]\n",
    "    # act: activation function\n",
    "    # Outputs size: batch_size*16*16*16*32 \n",
    "    dis_h0 = tl.layers.Conv3dLayer(dis_in, shape=[4,4,4,1,32],\n",
    "                                   W_init = initializer,\n",
    "                                   strides=[1,2,2,2,1], name='d/h0/conv2d')\n",
    "    # alpha: degree of leakiness used in leaky ReLU\n",
    "    dis_h0.outputs = tl.activation.leaky_relu(dis_h0.outputs, alpha=0.2, name='d/h0/lrelu')\n",
    "    #print '!!!dis_h0.outputs:',dis_h0.outputs \n",
    "    \n",
    "    # outputs size: batch_size*8*8*8*64 \n",
    "    dis_h1 = tl.layers.Conv3dLayer(dis_h0, shape=[4,4,4,32,64],\n",
    "                                   W_init = initializer,\n",
    "                                   strides=[1,2,2,2,1], name='d/h1/conv2d')\n",
    "    dis_h1 = tl.layers.BatchNormLayer(dis_h1, is_train=is_train, name='d/h1/batch_norm')\n",
    "    dis_h1.outputs = tl.activation.leaky_relu(dis_h1.outputs, alpha=0.2, name='d/h1/lrelu')\n",
    "    #print '!!!dis_h1.outputs:',dis_h1.outputs  \n",
    "    \n",
    "    # outputs size batch_size*4*4*4*128 \n",
    "    dis_h2 = tl.layers.Conv3dLayer(dis_h1, shape=[4,4,4,64,128],\n",
    "                                   W_init = initializer,\n",
    "                                   strides=[1,2,2,2,1], name='d/h2/conv2d')\n",
    "    dis_h2 = tl.layers.BatchNormLayer(dis_h2, is_train=is_train, name='d/h2/batch_norm')\n",
    "    dis_h2.outputs = tl.activation.leaky_relu(dis_h2.outputs, alpha=0.2, name='d/h2/lrelu')\n",
    "    #print '!!!dis_h2.outputs:',dis_h2.outputs   \n",
    "    \n",
    "    # outputs size batch_size*2*2*2*256 \n",
    "    dis_h3 = tl.layers.Conv3dLayer(dis_h2, shape=[4,4,4,128,256],\n",
    "                                   W_init = initializer,\n",
    "                                   strides=[1,2,2,2,1], name='d/h3/conv2d')\n",
    "    dis_h3 = tl.layers.BatchNormLayer(dis_h3, is_train=is_train, name='d/h3/batch_norm')\n",
    "    dis_h3.outputs = tl.activation.leaky_relu(dis_h3.outputs, alpha=0.2, name='d/h3/lrelu')\n",
    "    #print '!!!dis_h3.outputs:',dis_h3.outputs  \n",
    "    \n",
    "    # !!!!!! I have edited /Library/Python/2.7/site-packages/tensorlayer/layers.py to output dimension 2*2*2*256\n",
    "    # !!!!!! Remember to change this to according values when the discriminator's structure changed\n",
    "    #print '!!!',\n",
    "    #dis_h3.print_layers() # print all information about dis_h3\n",
    "    \n",
    "    # flatten the tensor to [batch_size, 2*2*2*256]\n",
    "    dis_flat = tl.layers.FlattenLayer(dis_h3, name='d/h4/flatten')\n",
    "    \n",
    "    # create a fully connect layer with dis_flat and just one node in the output layer\n",
    "    # note there's no batch normalization at this layer\n",
    "    # n_units: number of nodes in FC layer\n",
    "    dis_output = tl.layers.DenseLayer(dis_flat, n_units=1, act=tf.identity,\n",
    "                                    W_init=initializer,\n",
    "                                    name='d/h4/lin_sigmoid')\n",
    "    # outputs size: batch_size*1 \n",
    "    logits = dis_output.outputs\n",
    "    dis_output.outputs = tf.nn.sigmoid(dis_output.outputs)    \n",
    "    #print '!!!dis_output.outputs:',dis_output.outputs \n",
    "    #print '!!!logits:',logits \n",
    "    \n",
    "    return dis_output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting two networks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_size = 100 # size of initial noise vector that will be used for generator\n",
    "\n",
    "# initialize all parameters of the networks\n",
    "# weights were initialized from a zero-centered Normal distribution with standard deviation 0.02\n",
    "# tf.truncated_normal returns random values from a normal distribution and made sure no value exceeds 2 std\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "# placeholders for inputs into the generator and discriminator, respectively.\n",
    "z_vector = tf.placeholder(shape=[batch_size,z_size],dtype=tf.float32, name='z_vectors') \n",
    "x_vector = tf.placeholder(shape=[batch_size,32,32,32,1],dtype=tf.float32, name='real_chairs') \n",
    "\n",
    "\n",
    "# ---- DCGAN ----\n",
    "net_g_train = generator(z_vector, is_train=True, reuse=False) # generated mini-batch of images from noisy z vectors \n",
    "print 'generator: ',net_g_train\n",
    "#print 'generator outputs: ',net_g_train.outputs\n",
    "\n",
    "net_d, d_output_x = discriminator(x_vector, is_train=True, reuse=False) # probabilities for real images                !!! should have ,reuse=True when there's pre-training\n",
    "print 'discriminator: ',net_d\n",
    "d_output_x = tf.maximum(tf.minimum(d_output_x, 0.99), 0.01) # avoid inf and -inf\n",
    "summary_d_x_hist = tf.histogram_summary(\"d_prob_x\", d_output_x)\n",
    "\n",
    "net_d2, d_output_z = discriminator(net_g_train.outputs, is_train=True, reuse=True) # probabilities for generated images\n",
    "d_output_z = tf.maximum(tf.minimum(d_output_z, 0.99), 0.01) # avoid inf and -inf\n",
    "summary_d_z_hist = tf.histogram_summary(\"d_prob_z\", d_output_z)\n",
    "\n",
    "d_loss = -tf.reduce_mean(tf.log(d_output_x) + tf.log(1-d_output_z)) # loss for discriminator\n",
    "summary_d_loss = tf.scalar_summary(\"d_loss\", d_loss)\n",
    "\n",
    "g_loss = -tf.reduce_mean(tf.log(d_output_z)) # loss for generator\n",
    "summary_g_loss = tf.scalar_summary(\"g_loss\", g_loss)\n",
    "\n",
    "# this is generator for evaluation, set is_train to False so that BatchNormLayer behave differently\n",
    "net_g_test = generator(z_vector, is_train=False, reuse=True)\n",
    "\n",
    "\n",
    "# the following parameter indices may change if the network structure changes\n",
    "para_g=list(np.array(tf.trainable_variables())[[0,1,4,5,8,9,12,13]])\n",
    "para_d=list(np.array(tf.trainable_variables())[[14,15,16,17,20,21,24,25,28,29]])\n",
    "\n",
    "# only update parameters in discriminator during pre-training\n",
    "#pre_optimizer = tf.train.AdamOptimizer(learning_rate=alpha_d,beta1=beta1).minimize(d_pre_loss,var_list=para_d)\n",
    "# only update the weights for the discriminator network\n",
    "optimizer_op_d = tf.train.AdamOptimizer(learning_rate=alpha_d,beta1=beta1).minimize(d_loss,var_list=para_d)\n",
    "# only update the weights for the generator network\n",
    "optimizer_op_g = tf.train.AdamOptimizer(learning_rate=alpha_g,beta1=beta1).minimize(g_loss,var_list=para_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a log folder and save the graph structure, do this before training\n",
    "g_writer = tf.train.SummaryWriter(logs_path + '/generator', graph=tf.get_default_graph())\n",
    "d_writer = tf.train.SummaryWriter(logs_path + '/discriminator')\n",
    "\n",
    "# saver saves and loads variables of the model to and from checkpoints, \n",
    "# which are binary files that maps variable names to tensor values\n",
    "saver = tf.train.Saver(max_to_keep=50) \n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    # set GPU memeory fraction\n",
    "    tl.ops.set_gpu_fraction(sess=sess, gpu_fraction=0.99)\n",
    "    \n",
    "    # variables need to be initialized before we can use them\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    #print [v.name for v in tf.trainable_variables()] # print all variable names\n",
    "    #print 'para_g:',[v.name for v in para_g]\n",
    "    #print '\\n para_d:',[v.name for v in para_d]\n",
    "    \n",
    "    \n",
    "    # -------- jointly training discriminator and generator --------\n",
    "    start = time.time()\n",
    "    \n",
    "    # z noise vector that will be used to generate chairs to check the training progress\n",
    "    #z_sample = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) # uniform distribution between [-1, 1]\n",
    "    z_sample = np.random.normal(0, 0.33, size=[batch_size,z_size]).astype(np.float32) # gaussian distribution between [-1, 1]\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        # get a batch of real chairs, with range [-1 ,1]\n",
    "        x = get_x(batch_size) \n",
    "        # mini-batch of noise data from [-1, 1]\n",
    "        #z = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "        z = np.random.normal(0, 0.33, size=[batch_size,z_size]).astype(np.float32)\n",
    "    \n",
    "        # Update the discriminator and generator\n",
    "        d_summary_merge = tf.merge_summary([summary_d_loss, summary_d_x_hist,summary_d_z_hist])\n",
    "        summary_d,discriminator_loss = sess.run([d_summary_merge,d_loss],feed_dict={z_vector:z, x_vector:x})\n",
    "        summary_g,genterator_loss = sess.run([summary_g_loss,g_loss],feed_dict={z_vector:z})  \n",
    "        #print \"epoch: \", epoch\n",
    "        #print 'd_loss:',discriminator_loss\n",
    "        #print 'g_loss:',genterator_loss\n",
    "        \n",
    "        # only update the discriminator when its loss is larger than 10%       !!!!! D may not get sufficiently trained if threshold is too high\n",
    "        if discriminator_loss <= 4.6*0.1: \n",
    "            sess.run([optimizer_op_g],feed_dict={z_vector:z})\n",
    "            #print \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',genterator_loss\n",
    "        # only update the generator when its loss is larger than 10%       !!!!! G may not get sufficiently trained if threshold is too high\n",
    "        elif genterator_loss <= 4.6*0.1:\n",
    "            sess.run([optimizer_op_d],feed_dict={z_vector:z, x_vector:x})\n",
    "            #print \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',genterator_loss\n",
    "        else:\n",
    "            sess.run([optimizer_op_d],feed_dict={z_vector:z, x_vector:x})\n",
    "            sess.run([optimizer_op_g],feed_dict={z_vector:z})\n",
    "        \n",
    "        # add loss summary to tensorboard\n",
    "        if epoch % 5 == 0:\n",
    "            d_writer.add_summary(summary_d, epoch) \n",
    "            g_writer.add_summary(summary_g, epoch)\n",
    "        \n",
    "        # print training progress\n",
    "        if epoch % 100 == 0:\n",
    "            time_lapse = time.time()-start\n",
    "            start = time.time()\n",
    "            print \"epoch: \", epoch,\", time spent: %.2fs\" % time_lapse\n",
    "            \n",
    "        # output generated chairs\n",
    "        if epoch % 500 == 0:\n",
    "            g_chairs = sess.run(net_g_test.outputs,feed_dict={z_vector:z_sample}) # get a generated chair, with range [-1, 1]\n",
    "            # make a directory for generated chairs\n",
    "            if not os.path.exists(train_sample_directory):\n",
    "                os.makedirs(train_sample_directory)\n",
    "            \n",
    "            #Save sample generated chair arrays\n",
    "            g_chairs.dump(train_sample_directory+'/'+str(epoch))\n",
    "        \n",
    "        # save model check point\n",
    "        if epoch % 500 == 0:\n",
    "            # make a directory for trained models\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            \n",
    "            # save the trained model at different epoch\n",
    "            saver.save(sess, save_path = model_directory + '/' + str(epoch) + '.cptk')\n",
    "    print \"Done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Continue training from the last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "ckpt.all_model_checkpoint_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ckpt.all_model_checkpoint_paths[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Loading models...might take a minute'\n",
    "saver = tf.train.Saver(max_to_keep=50)\n",
    "\n",
    "# create a log folder and save the graph structure, do this before training\n",
    "g_writer = tf.train.SummaryWriter(logs_path + '/generator', graph=tf.get_default_graph())\n",
    "d_writer = tf.train.SummaryWriter(logs_path + '/discriminator')\n",
    "\n",
    "with tf.Session() as sess:  \n",
    "    # set GPU memeory fraction\n",
    "    tl.ops.set_gpu_fraction(sess=sess, gpu_fraction=0.99)\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    #model = ckpt.all_model_checkpoint_paths[3]\n",
    "    model = ckpt.model_checkpoint_path\n",
    "    saver.restore(sess, save_path=model)\n",
    "    \n",
    "    # -------- jointly training discriminator and generator --------\n",
    "    start = time.time()\n",
    "    \n",
    "    # z noise vector that will be used to generate chairs to check the training progress\n",
    "    #z_sample = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32) # uniform distribution between [-1, 1]\n",
    "    z_sample = np.random.normal(0, 0.33, size=[batch_size,z_size]).astype(np.float32) # gaussian distribution between [-1, 1]\n",
    "    \n",
    "    for epoch in range(4000, 25001):\n",
    "        # get a batch of real chairs, with range [-1 ,1]\n",
    "        x = get_x(batch_size) \n",
    "        # mini-batch of noise data from [-1, 1]\n",
    "        #z = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "        z = np.random.normal(0, 0.33, size=[batch_size,z_size]).astype(np.float32)\n",
    "    \n",
    "        # Update the discriminator and generator\n",
    "        d_summary_merge = tf.merge_summary([summary_d_loss, summary_d_x_hist,summary_d_z_hist])\n",
    "        summary_d,discriminator_loss = sess.run([d_summary_merge,d_loss],feed_dict={z_vector:z, x_vector:x})\n",
    "        summary_g,genterator_loss = sess.run([summary_g_loss,g_loss],feed_dict={z_vector:z})  \n",
    "        #print \"epoch: \", epoch\n",
    "        #print 'd_loss:',discriminator_loss\n",
    "        #print 'g_loss:',genterator_loss\n",
    "        \n",
    "        # only update the discriminator when its loss is larger than 10%   !!!!! D may not get sufficiently trained if threshold is too high\n",
    "        if discriminator_loss <= 4.6*0.1: \n",
    "            sess.run([optimizer_op_g],feed_dict={z_vector:z})\n",
    "            #print \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',genterator_loss\n",
    "        # only update the generator when its loss is larger than 10%       !!!!! G may not get sufficiently trained if threshold is too high\n",
    "        elif genterator_loss <= 4.6*0.1:\n",
    "            sess.run([optimizer_op_d],feed_dict={z_vector:z, x_vector:x})\n",
    "            #print \"epoch: \",epoch,', d_loss:',discriminator_loss,'g_loss:',genterator_loss\n",
    "        else:\n",
    "            sess.run([optimizer_op_d],feed_dict={z_vector:z, x_vector:x})\n",
    "            sess.run([optimizer_op_g],feed_dict={z_vector:z})\n",
    "            \n",
    "        # add loss summary to tensorboard\n",
    "        if epoch % 10 == 0:\n",
    "            d_writer.add_summary(summary_d, epoch) \n",
    "            g_writer.add_summary(summary_g, epoch)\n",
    "        \n",
    "        # print training progress\n",
    "        if epoch % 100 == 0:\n",
    "            time_lapse = time.time()-start\n",
    "            start = time.time()\n",
    "            print \"epoch: \", epoch,\", time spent: %.2fs\" % time_lapse    \n",
    "        \n",
    "        # output generated chairs\n",
    "        if epoch % 500 == 0:\n",
    "            g_chairs = sess.run(net_g_test.outputs,feed_dict={z_vector:z_sample}) # get a generated chair, with range [-1, 1]\n",
    "            # make a directory for generated chairs\n",
    "            if not os.path.exists(train_sample_directory):\n",
    "                os.makedirs(train_sample_directory)\n",
    "            \n",
    "            #Save sample generated chair arrays\n",
    "            g_chairs.dump(train_sample_directory+'/'+str(epoch))\n",
    "        \n",
    "        # save model check point\n",
    "        if epoch % 500 == 0:\n",
    "            # make a directory for trained models\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            \n",
    "            # save the trained model at different epoch\n",
    "            saver.save(sess, save_path = model_directory + '/' + str(epoch) + '.cptk')\n",
    "    print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read generated samples and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples=np.load('8000')\n",
    "chair = samples[3]\n",
    "chair=chair.reshape([32,32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print chair.min(),chair.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chair=chair.round() # round values to 0.0 or 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn a voxel 3d array into mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stl import mesh\n",
    "from skimage import measure\n",
    "# Use marching cubes to obtain the surface mesh of these ellipsoids\n",
    "# level is a float number between the min and max of chair\n",
    "# the lower the level is, the more detail of voxels are captured; the higher, the less noise in the volumetric model\n",
    "vertices, faces = measure.marching_cubes(chair,level=0.5)\n",
    "\n",
    "# Create the mesh and save as STL\n",
    "chair = mesh.Mesh(np.zeros(faces.shape[0], dtype=mesh.Mesh.dtype))\n",
    "for i, f in enumerate(faces):\n",
    "    for j in range(3):\n",
    "        chair.vectors[i][j] = vertices[f[j],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot out the meshed object\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import pyplot\n",
    "\n",
    "figure = pyplot.figure()\n",
    "axes = mplot3d.Axes3D(figure)\n",
    "\n",
    "# Load the STL files and add the vectors to the plot\n",
    "axes.add_collection3d(mplot3d.art3d.Poly3DCollection(chair.vectors))\n",
    "\n",
    "# Auto scale to the mesh size\n",
    "scale = chair.points.flatten(-1)\n",
    "axes.auto_scale_xyz(scale, scale, scale)\n",
    "\n",
    "# Show the plot to the screen\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the mesh to STL file \n",
    "chair.save('chair.stl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the trained generator to genrate chair models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_directory = './3d_gan/models/' # directory to save trained model\n",
    "sample_inter_directory = './3d_gan/interpolation/' # directory to save the generated models from interpolation\n",
    "# make a directory for generated images\n",
    "if not os.path.exists(sample_inter_directory):\n",
    "    os.makedirs(sample_inter_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# size of initial noise vector that will be used for generator\n",
    "z_size = 100 \n",
    "# placeholders for inputs into the generator\n",
    "# shape[0] is None means size could take any integer value\n",
    "z_vector = tf.placeholder(shape=[None,z_size],dtype=tf.float32, name='z_vectors')\n",
    "\n",
    "# initialize all parameters of the networks\n",
    "# weights were initialized from a zero-centered Normal distribution with standard deviation 0.02\n",
    "# tf.truncated_normal returns random values from a normal distribution and made sure no value exceeds 2 std\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "net_g_test = generator(z_vector, is_train=False, reuse=False)\n",
    "\n",
    "print 'Loading Face models...might take a minute'\n",
    "saver = tf.train.Saver()\n",
    "print 'done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stl import mesh\n",
    "from skimage import measure\n",
    "    \n",
    "# spherical interpolation between pointA and pointB, each is a ndarray\n",
    "# val is a value between [0,1], where 0 returns pointA, 1 returns pointB\n",
    "def slerp(val, pointA, pointB):\n",
    "    omega = np.arccos(np.clip(np.dot(pointA/np.linalg.norm(pointA), pointB/np.linalg.norm(pointB)), -1, 1))\n",
    "    so = np.sin(omega)\n",
    "    if so == 0:\n",
    "        return (1.0-val) * pointA + val * pointB # L'Hopital's rule/LERP\n",
    "    return np.sin((1.0-val)*omega) / so * pointA + np.sin(val*omega) / so * pointB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # reload the trained model.\n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    model = ckpt.model_checkpoint_path #  read the model saved at epoch 8000\n",
    "    print 'load model: ', model\n",
    "    # restore model variables\n",
    "    saver.restore(sess, save_path=model)\n",
    "\n",
    "    # z noise vector that will be used to generate image to check the training progress\n",
    "    z_sample = np.random.normal(0, 0.33, size=[batch_size,z_size]).astype(np.float32) # gaussian distribution between [-1, 1]\n",
    "    #print z_sample.shape\n",
    "    # linear interpolation\n",
    "    #z_sample_one = z_sample[:1]\n",
    "    #print z_sample_one.shape\n",
    "    \n",
    "    g_chairs = sess.run(net_g_test.outputs,feed_dict={z_vector:z_sample}) # get a generated chair, with range [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_chairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chair = g_chairs[3].reshape([32,32,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn voxel into mesh\n",
    "# Use marching cubes to obtain the surface mesh of these ellipsoids\n",
    "# level is a float number between the min and max of chair\n",
    "# the lower the level is, the more detail of voxels are captured; the higher, the less noise in the volumetric model\n",
    "vertices, faces = measure.marching_cubes(chair,level=0.5)\n",
    "\n",
    "# Create the mesh and save as STL\n",
    "chair = mesh.Mesh(np.zeros(faces.shape[0], dtype=mesh.Mesh.dtype))\n",
    "for i, f in enumerate(faces):\n",
    "    for j in range(3):\n",
    "        chair.vectors[i][j] = vertices[f[j],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot out the meshed object\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import pyplot\n",
    "\n",
    "figure = pyplot.figure()\n",
    "axes = mplot3d.Axes3D(figure)\n",
    "\n",
    "# Load the STL files and add the vectors to the plot\n",
    "axes.add_collection3d(mplot3d.art3d.Poly3DCollection(chair.vectors))\n",
    "\n",
    "# Auto scale to the mesh size\n",
    "scale = chair.points.flatten(-1)\n",
    "axes.auto_scale_xyz(scale, scale, scale)\n",
    "\n",
    "# Show the plot to the screen\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
